#!/bin/bash

banner() {

 
    while read -r line; do
    	printf "\033[1;31m\e[%s\033[0m\n" "$line"
    done <<-EOF
    _    ____                      ;
    _   /---.'.__             ____//
    _        '--.\           /.---'
    _   _______  \!         //
    _ /.------.\  \|      .'/  ______
    _//  ___  \ \ ||/|\  //  _/_----.\__
    _|/  /.-.\  \ \:|< >|// _/.'..\   '--'
    _'  //   !'. | !'.|.'/ /_/ /  \!
    _  //     \ \_\!" ' ~\-'.-'    \!
    _ //       '-._| :H: |'-.__     \!
    _//           (!'==='!)'-._\     ||
    _||                        \!    \|
    _||      crawl@synacktra    \!    '
    _|/                          \!
    _'     Author: Harsh Verma    ||
    _                            ||
    _                            \|
    _                             '
EOF
printf "see help menu: %s -h\n" "${0##*/}"
}

[ -z "$*" ] && banner


help_text () {

    while read -r line; do
        printf "%s\n" "$line"
    done <<-EOF
	
    |Usage:
    |  ${0##*/} [-f] (href|script) 
    |
    |Options:
    |  -h show help menu
    |  -f fetch a type of link. [href|script]
    |
    |Example:
    |  crawl -f script [domain].[TLD]
    |  crawl [domain].[TLD]/directory
    |  crawl -f href [domain].[TLD]/directory?key=value
    |
    |By default, crawl fetches both href and script links.
    |If no protocol specified, it uses HTTPs as default.
EOF
}

fetch="(href|<script.*src)"

while getopts 'hf:' OPT; do
    case $OPT in
        f) 
            case "$OPTARG" in
		script)
		    fetch="<script.*src" ;;
		href)
		    fetch="href" ;;
		*)
		    help_text
		    exit 1
		    ;;
	     esac
	     ;;
	 h|*)
	     help_text
	     exit 0
	     ;;
    esac
done

[ "$#" -eq 2 ] && printf "\033[31m%s\033[0m\n" "No URL detected!" >&2 && exit 1

url=$(printf "%s" "${@: -1}")
[[ ! "$url" =~ http[s]?:// ]] && url="https://$url"

agent="Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/108.0.0.0 Safari/537.36"

crawl() {

    base_url=$(printf "%s" "$1" | awk -F "?|#" '{print $1}')
    [[ $base_url =~ .*/ ]] && base_url=$(printf "%s" $base_url | sed 's#.$##g') 
	
    curl -H 'Accept: text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8' \
         -H 'Accept-Language: en-GB,en-US;q=0.8,en;q=0.6' -A "$agent" -sL "$1" | \
         grep -Eo "$fetch=[\"'][^\"']+" | sed -E -e "s^[[:space:]]^%20^g" \
	 -e "s@$fetch=[\"'](/|\./)?@@" \
         -e "s!^/.*!https:/&!" \
	 -e "s!^\.\./(.*)!$(printf "%s" $base_url | grep -Eo '.*/')\1!" \
	 -e "/^(http|tel)/!s!.*!$base_url\/&!"

}


cache=($(crawl "$url"))

for obj in "${cache[@]}"; do

    printf "\033[1;31m%s\033[0m\n" "$obj"
    [[ "$obj" =~ $url[/]?$ ]] && continue
    [[ "$obj" =~ ^http.* ]] && crawl "$obj"
done

